Engineering Privacy for Verified Credentials: 
In Which We Describe Data Minimization, Selective Disclosure and Progressive Trust 
==============================

Contributors:
PENDING IPR AND "RESPECT FORMAT" APPROVALS

* Lionel Wolberger, Independent
* Brent Zundel, Evernym/Sovrin
* Zachary Larson, Independent
* Irene Hernandez, Independent 
* Katryna Dow, Meeco

# Introduction

This paper explains how privacy can be enhanced while credential attributes are shared electronically. We explain three related but distinct privacy enhancements of "data minimization," "selective disclosure," and "progressive trust." We describe in plain English, but with some rigor, techniques that enable these enhancements. We also show what we are talking about in diagrams and animations, to visualize the communication flows. 

Our goal is to enable decision makers, particularly non-technical ones, to gain a nuanced grasp of these enhancements along with some idea of how their enablers work. We include enough detail for those who wish to dive deeper. This knowledge will, in the end, lead readers of this paper to be better able to know when they need privacy enhancements, what type of enhancement best suits the use case, assess techniques that enable those enhancements, and adopt the correct enhancement for the correct use case. 

## Three examples

To grasp the problem, here are three examples of how people would like privacy preserved in the process of sharing credentials.

Diego attempts to login to an online service and is asked for his Facebook name. He knows that the service may read from his Facebook account a broad range of data without meaningful consent on his part. Diego hesitates, since the service doesn't need everything in his Facebook account. Thoughts pass through his mind: What data will this service read in order to complete the login? What will it read in future? Is there a way for him to login with his Facebook data while revealing only a minimal amount of information? 

Selena hands her driver's license to a bouncer to prove she is of drinking age. As he looks it over, she sees him inspecting her date of birth and home address. He only needs to know that she is over 21. Is there a way to disclose that she is indeed old enough without revealing her actual age, along with her home address and city of residence as well? 

In negotiations with a real estate agent to purchase a home, Proctor reveals a letter from his bank stating his credit limit. He wanted to reveal its approximate amount only, but the agent insisted on verifying that the letter was authentic. Proctor feels the agent now has the upper hand in the negotiation, as the letter reveals more than just its authenticity. Could he have revealed only an approximate amount, and reveal more details as the negotiations progress?

Each story highlights the need for a particular privacy enhancement addressed in this paper: Diego's highlights the need for "data minimization," Selena's for "selective disclosure," and Proctor's for "progressive trust." 

## What are credentials and attributes?
A credential is a statement of information relating to a subject, such as "my age." To be more precise, "a qualification, achievement, quality, or piece of information about an entity's background." Such a credential describes a quality or qualities, property or properties of an entity which establish its existence and uniqueness. A credential has an issuer, inspector, subject and holder. Examples include a name, government ID, payment provider, home address, or university degree. 

An attribute is a value associated with a credential. For example, "January 1, 1980" is a date that could be an attribute associated with a birthday. 

## What are verifiable credentials?
A verifiable credential is a credential that is effectively tamper-proof, and whose authenticity can be verified in an automated fashion.  
## Do attributes need to be formatted for privacy-enhancement?
Privacy enhancement is made possible by the use of standardized formats. 

Privacy becomes an issue when credentials are shared and inspected. It is when the credential is verified that it is exposed to inspection and our privacy concerns are brought to bear. It is then that machine processes can assist in privacy enhancement, provided that they can understand and work with the data in question. 

The World Wide Web community has standardized many data formats. Some were standardized to enable search engines to understand the information on web pages and provide richer search results. While unformatted data can be interpreted by using data extraction methods, these can be error prone because information can be represented in so many different ways. 

## What is the role of numbers? Do attributes need to be numeric?  
All electronic information is ultimately stored as numbers. The ability of a system to enhance privacy depends on the kinds of numbers involved. Current practice identifies three main kinds of numbers.

* Nominal numbers answer the question, "what is the identifier?"
* Ordinal numbers answer the question, "in what order?"
* Cardinal numbers answer the question, "how many?"

Numbers that name things are like the number 012 representing the letter, "A," according to ASCII, or telephone numbers and sports team jersey numbers. Called "nominal," from the word for name, these numbers identify things and act like names. They do not reflect a quantity, or a preferred ranked order. Some numbers account for a rank or position, called "ordinal," from the word for order. These numbers' are intended to state their position or rank in relation to a set of other numbers—3rd fastest runner, 6th in line, or 1st letter of the alphabet. Numbers that count quantities, confusingly called "cardinal," from the word for "chief," tell "how many" we have: 8 puppies, 14 friends or 26 letters of the English alphabet. Cardinal numbers resemble ordinal—3rd is more than 2nd—but they differ in subtle ways that are important to data minimization.

To illustrate why these differences between numbers are important, imagine you are buying a car, you open your bank account page and it says "52433". Is this number nominal, the name of your bank account? Is it ordinal, showing the 52,433rd transaction of the day? Or is it a quantity, perhaps your bank balance showing that you have $52,433.00? Privacy enhancement strategies will differ, depending on the numeric qualities. 

Our ability to enhance privacy depends in the end on these differences in the kinds of numbers representing our credential attributes.

##Do we need cryptography?

Yes we do. Cryptography makes privacy enhancement possible in electronic communication. In privacy enhancement of credentials, some data parts are revealed while others are concealed. Concealment is achieved mostly by the art of cryptography, from the greek word "kryptos," meaning hidden, like in a crypt.

(For the remainder of this paper, we use the short word "crypto" to refer to the use of cryptographic algorithms to achieve our privacy enhancing goals.)

### Crypto Goals 
Privacy-enhancing cryptography has four primary goals.

* **Confidentiality**: a hidden part of a credential cannot be understood by anyone for whom it is unintended. Often called "privacy," we avoid that word here since it can mean many thingsz in addition to confidentiality. 
* **Authentication**: the identity of information shared can be validated as authentic. 
* **Integrity**: the revealed part of the credential cannot be altered without such alteration being detected. Also known as validity, fidelity or verifiability. 
* **Non-repudiation**: aka non-deniability, a credential's creator cannot deny at a later stage his or her involvement.

### How does crypto Work?
Crypto enables us to achieve our goals by means of clever application of three primary enablers: the management of secrets, the curation of puzzles of various levels of difficulty, and the use of zero knowledge protocols. This terminology, while highly simplified, will help the lay reader understand just how privacy enhancement works. 

Let's consider the "Where's Waldo?" series of visual puzzles to understand these three enablers. On each page of these books a distinctively dressed man in a striped hat appears at a stop on his "world-wide hike". Somewhere amid each densely illustrated crowded scene is Waldo and readers are asked to scour the page and locate the lost traveler. 

* **Secret management**: For the new reader, Waldo's location is a secret: the illustrator knows it, and the reader doesn't. One could raid the publisher's offices and perhaps find the secret stored somewhere. On the other hand, a reader can search and finally find Waldo. That reader could keepthe information secret by circling him in red and putting the book in a safe. Secrets in cryptography are usually called "keys," and a "private key" is a particular kind of secret that must be managed. 
* **Difficulty**: Waldo puzzles are difficult to solve yet easy to verify. That's why it is a puzzle! The reader has to search everywhere and mistakenly eye many Waldo look-alike characters  before reaching a satisfactory finish and finding him. But checking if Waldo was found is rather simple. Just point to Waldo and a verifier can instantly see--there he is. This difference between the difficulty of solving as opposed to verifying is a core concept in computational complexity, and lies at the heart of cryptographic enablers. 
* **Zero knowledge**: Anyone can prove that they found Waldo without revealing the secret of his actual location on the page. To do so, take a huge white rectangular piece of white cardboard that is much larger than the book. Cut a hole exactly fitting Waldo, that reveals only his silhouette and nothing else. One can now show Waldo to any verifier: there he is! Yet the cardboard is so wide, hiding the book so well, a verifier has no idea where Waldo is on the page's illustration. A verifier can say without any doubt yes, the reader has indeed found Waldo, because Waldo is right there. The puzzle was solved and someone verified the achievement, without revealing any knowledge of how to solve the puzzle. This is a zero knowledge proof, an useful capability in privacy enhancement. 

Using this vocabulary we may say: to enhance the privacy of an age credential (I am older than 21 years), a credential holder has a secret to manage. This secret key is applied to hide her birthday in various difficult mathematical puzzles. The puzzles are crafted in such a way that it is easy to verify one's age, but quite difficult to determine the exact date of birth. The inspector performs a zero knowledge proof on those puzzles and determines the credential is valid, without revealing the birthdate itself.


# Privacy enhancement strategies
We have three strategies for enhancing privacy while credential attributes are shared: data minimization, selective disclosure and progressive trust. 

## Data minimization
Data minimization is the act of limiting the amount of shared data strictly to the minimum necessary in order to successfully accomplish a task or goal. 

Minimization has three types:

* Content minimization – the amount of data should be strictly the minimum necessary.
* Temporal minimization – the data should be stored by the receiver strictly during the minimum amount of time necessary to execute the task
* Scope minimization – the data should only be used for the strict purpose of the active task. 
Data minimization is largely a policy decision.

Data minimization capabilities impact the credentials ecosystem in the following ways.

* issuer: ensure that the credential is presented in such a way as to enable data minimization. This may require issuing multiple, related, atomic sub-credentials. 
* inspector: establish in advance policies regarding:
	* what is the minimum data necessary to accomplish the task or goal. 
	* what is the minimum time the data can be stored to execute the task
	* how to ensure that the data is applied only to that task and does not, by a process of scope creep, become applied to other tasks or goals.

## Selective disclosure
Selective disclosure is the ability of an individual to granularly decide what information to share. Selective disclosure is a means by which data minimization can be achieved.

Selective disclosure capabilities impact the credentials ecosystem in the following ways.

* issuer: format the credential in such a way as to enable selective disclosure. This may require issuing multiple, related, atomic sub-credentials. It also may require formatting the credential to support mathematical queries and cryptographic proofs
* inspector: ensure the request is framed in such a way as to enable selective disclosure. (This is a data minimization task that impacts selective disclosure). What is the way to request the credential that would enable a subject to selectively disclose the minimum data necessary to accomplish the task or goal. 

## Progressive trust
Progressive trust is the ability of an individual to gradually increase the amount of relevant data revealed as trust is built or value generated. 

Progressive trust capabilities impact the credentials ecosystem in the following ways.

* issuer: format the credential(s) in such a way as to enable progressive trust. This may require issuing multiple, related, atomic sub-credentials. It also may require formatting the credential to support mathematical queries and cryptographic proofs. Finally, it requires a data model expressing how the various sub-credentials are related in a scenario involving progressive trust. 
* inspector: ensure that requests are framed in such a way as to enable progressive trust. (This requires the first two enablers, data minimization and selective disclosure as well). Structure the communication in order to to gradually escalate credential requests in such a way that would enable a subject to progressively trust the inspector more and more, revealing the minimum data necessary to accomplish each step of the task or goal, and reveal more and more as our communication progresses. 


# Implementations
Follow the process step-by-step by viewing the diagrams.

### Code for [Web Sequence Diagram](https://www.websequencediagrams.com/):
Copy and paste the code below into the [Web Sequence Diagram](https://www.websequencediagrams.com/) webpage to generate the flow diagram. 

~~~~

title Verifiable credential using Selective Disclosure
participant Valid Time Oracle
participant Janet
participant ID Provider
participant Ledger
participant Bar

note over Janet:Prover
note over Bar:Validator

note over Janet,Bar: Preparation and Setup

note right of ID Provider:Infrastructure
ID Provider->Ledger: Define Schema (Name, Birthdate, Address)
ID Provider->Ledger: credential Definition (Pub Key, etc.)
ID Provider->ID Provider: Generate Prv Key for this credential
ID Provider->Ledger:Revocation Registry

note left of Bar: Prepare to accept credentials
Bar->Bar:Install Agent
Bar->Ledger: Check schema

note over Janet,Bar: Begin Use Case
Janet->ID Provider: Request ID
ID Provider-->Janet: ID will be issued as a digital credential
note right of Janet: Prepare to receive credentials
Janet->Janet: Install Agent
Janet->Janet: Prv Key Generate, Store
Janet->Ledger:Check Schema
Ledger->Janet:credential Definition
Janet-->ID Provider:Proof of Name, Birthdate, Address
Janet->ID Provider: Blinded secret
ID Provider->Janet: credential
Janet->Janet: Validate credential against credential Def

note over Janet,Bar: Janet goes to the bar
note left of Bar: Can Janet Enter?
Bar->Janet: Request Proof of Age
Janet->Valid Time Oracle: Get time
Valid Time Oracle->Janet: Time credential
Janet->Janet:Generate Proof (This person is over 21)
Janet->Bar: Provide Proof
Bar->Bar: Evaluate proof
Bar->Ledger: Verify on Ledger
Ledger->Bar: Verification
Bar->Janet: Come in

note left of Bar: Invite to club

Bar->Janet: Join loyalty club? (requires valid postal code)
Janet->Janet:Generate Proof (postal code)
Janet->Bar: Provide Proof
Bar->Bar: Evaluate proof
Bar->Ledger: Verify on Ledger
Ledger->Bar: Verification
Bar->Janet: Have Loyalty Card

~~~~

# Methods
This section shows an implementation of verifiable credentials that allows for privacy enhancement of credential attributes. In order facilitate understanding of the implementation, we first provide a section providing a view of topics in number theory and cryptography.

## Background
Cryptography is a huge field with highly specialized jargon, too much to cover here. But non-specialists would benefit from some understanding of relevant crypto in order to make informed decisions. This section describes basic concepts that enable users of verifiable credentials to understand the most critical cryptographic concepts. 

We begin with a brief overview of several concepts from number theory that serve as a foundation for all crypto used in this process. This is a curated list of topics progressing from the simple to the more complex. Notice how ideas are re-used and layered as read on. 

### Number Theory
Number theory refers to the study of the behavior of integer numbers such as 1, 2, 500. The following are behaviors of these numbers that make them useful for crypto:

* Prime or not: A prime number is divisible by only itself and 1. 
* One way function: A numerical function that takes a publicly known number, and without any secret information, computes a value. Like a one way street, computation goes only one way. Given that value, it is hard to find the publicly known number. 
* Modular arithmetic, aka clock arithmetic: a system of arithmetic where numbers "wrap around" upon reaching a certain value. A familiar use is in the 12-hour clock, in which our day is divided into 12-hour periods. If the time is 7:00 now, then 8 hours later it will be 3:00. 7 + 8 equals 15, but this is not the answer because clock time "wraps around" every 12 hours. 
* Groups and Finite Fields: A subset of all integers can form a group, which behaves in ways very useful to the performance of cryptography. In extremely simplified terms, a group is a self-sufficient set of integers, and any possible manipulation has an answer from within the group. Finite fields are types of groups that satisfy certain demanding properties. 
* Discrete Logarithms: A discrete logarithm is a property for numbers in a group. Since there is no efficient method for computing discrete logarithms, they are very useful in cryptography. (The logarithm log(b) of a is an exponent x such that b^x (b raised to the x exponent) = a.)
* Quadratic Residues: Quadratic refers to 'squared' numbers, a number raised to the second exponential power. Quadratic residues are a useful property of squared numbers as they behave in modular arithmetic. 

In crypto, these numeric properties are exploited to enable secret management, difficult puzzles that are easy to verify, and zero knowledge. 

### The Crypto Zoo

Each crypto process is named, and as time goes on hundreds if not thousands of protocols, processes, algorithms and protocols accumulate. We present here a brief tour of the most significant ones in our field of verifiable credentials:

* PKI, or "public and private keys": A person with a private key can, with the right software, participate in PKI (public key infrastructure) crypto. PKI processes like "digital signature," "authentication," and "certificate validation," all use PKI commands which in turn are locked to, or encumbered by, a private key that is kept secret. 
* Elliptic-curve cryptography (ECC) is an approach to public-key cryptography based on the numeric structure of elliptic curves over finite fields. ECC is useful as it require smaller keys compared to non-ECC cryptography. There are many variants of ECC used including Edwards-curve Digital Signature Algorithm (EdDSA) which uses a variant of Schnorr signature based on Twisted Edwards curves.
* Hash or message digest: One way functions, such as SHA 256. A Merkle tree is a set of many one way functions applied to a tree of data in which every leaf node is labelled with the hash of a data block and every non-leaf node is labelled with the cryptographic hash of the labels of its child nodes. 
* Signature: A signature in this context is a use of PKI. A signature can prove authenticity, integrity and non-repudiation of a message since a valid digital signature gives a recipient reason to believe that the message was created by a known sender (authentication), that the sender cannot deny having sent the message (non-repudiation), and that the message was not altered in transit (integrity). Signatures enable every cryptographic objective except for confidentiality. There are many types of signature schemes in use including Digital Signature Algorithm (DSA), Camenisch-Lysyanskaya (CL) signatures, and Boneh–Lynn–Shacham (BLS) signatures. 
* Key exchange: exchange methods enable two parties that have no prior knowledge of each other to jointly establish a shared secret key over an insecure channel. This key can then be used to encrypt subsequent communications using a symmetric key cipher. Diffie–Hellman is a common example. 
* Zero-Knowledge (ZK): Many ZK methods are used in cryptography incuding Fiat Shamir, Proof of knowledge of discrete logarithms, ZK Snarks, ZK Starks.
* Cryptographic accumulators: one way membership functions that answer a query as to whether a potential candidate is a member of a set without revealing the individual members of the set. Similar to a one-way hash function, cryptographic accumulators generate a fixed-size digest representing an arbitrarily large set of values. Some further provide a fixed-size witness for any value of the set, which can be used together with the accumulated digest to verify its membership in the set.  
* Commitments
* Witness: The term has different applications in cryptography. In this paper a witness is a value used in a cryptographic accumulator. In bitcoin the unlocking signature is called the "witness data." 
* Quantum Computing and Cryptography: as quantum computing is developed it poses a threat to the difficulty of puzzles. For example Shor's algorithm for integer factorization on quantum computers makes it much easier to discover a number's prime factors.



## Verifiable Credentials in Sovrin
Below is some of the detailed mathematics involved in issuing a verifiable credential as implemented by Sovrin, a non-profit organization dedicated to managing a decentralized, public network for the purposes of self-sovereign identity.

### Issuer setup
The following setup is a necessary precursor to issuing a privacy-preserving credential.

#### Compute
Perform the mathematical calculations required to curate the essential ingredients of the operations we are about to perform. Some of these results like the private keys are very sensitive and must be kept secret by the credential holder; others are to be shared.

* Random 𝓹', 𝓺', 1024 bit prime numbers such that 𝓹 = 2𝓹' + 1 and 𝓺 = 2𝓺' + 1 are both 1024 bit prime numbers.
* 𝓷 = 𝓹𝓺.
* Random quadratic residue: 𝓢 mod 𝓷
* Random 𝓧<sub>𝓩</sub>, 𝓧<sub>𝓡1</sub>, . . . , 𝓧<sub>𝓡𝓵</sub> ∈ \[2: 𝓹'𝓺' - 1\], where 𝓵 is the number of attributes in the credential.
* 𝓩 = 𝓢<sup>𝓧𝓩</sup> mod 𝓷
* 𝓡<sub>𝓲</sub> = 𝓢<sup>𝓧𝓡𝓲</sup> mod 𝓷, 1 ≤ 𝓲  ≤ 𝓵
* Issuer private key 𝓼𝓴<sub>𝓬</sub> =  𝓹'𝓺'
* Issuer public key 𝓹𝓴<sub>𝓬</sub> = {𝓷, 𝓢, 𝓩, 𝓡<sub>1</sub>, . . . , 𝓡<sub>𝓵</sub> }

#### Proof of Correctness
As a result of the above computations, we then curate the following. This proof, along with the public keys, is the computational algorithm that will be used to validate the credential.

* Random 𝓧'<sub>𝓩</sub>, 𝓧'<sub>𝓡1</sub>, . . . , 𝓧'<sub>𝓡𝓵</sub> ∈ \[2: 𝓹'𝓺' - 1\]
* 𝓩' = 𝓢<sup>𝓧'𝓩</sup> mod 𝓷
* 𝓡'<sub>𝓲</sub> = 𝓢<sup>𝓧'𝓡𝓲</sup> mod 𝓷, 1 ≤ 𝓲  ≤ 𝓵
* 𝓬  = 𝓗𝓪𝓼𝓱 ( 𝓩 || 𝓡<sub>1</sub> || . . . || 𝓡<sub>𝓵</sub> || 𝓩' || 𝓡'<sub>1</sub> || . . . || 𝓡'<sub>𝓵</sub> )
* 𝓧''<sub>𝓩</sub> = 𝓧'<sub>𝓩</sub> + 𝓬 𝓧<sub>𝓩</sub>
* 𝓧''<sub>𝓡𝓲</sub> = 𝓧'<sub>𝓡𝓲</sub> + 𝓬 𝓧<sub>𝓡𝓲</sub> , 1 ≤ 𝓲  ≤ 𝓵

##### The Cred Def is comprised of the public key and the proof of correctness, this is published to the distributed ledger

### Issuing a Credential
With setup complete, we can now issue the credential in a privacy-preserving manner.

#### For each credential
For each credential issued, perform the following operations.

##### Issuer computes:
A cryptographic accumulator is constructed in order to enable zero knowledge queries further on. It is a one way membership function, including the claim in the membership set. The operation can then answers a query as to whether a potential candidate is a member of a set without revealing the individual members of the set.

* 𝓐<sub>𝓲</sub> = accumulator index
* 𝓤<sub>𝓲</sub> = user index
* 𝓶<sub>2</sub> = 𝓗𝓪𝓼𝓱 ( 𝓐<sub>𝓲</sub>  || 𝓤<sub>𝓲</sub> )
* 256-bit integer representations of each of the attributes: 𝓶<sub>3</sub> , . . . , 𝓶<sub>𝓵</sub>
* 𝓷<sub>0</sub> = nonce

##### Issuer sends 𝓷<sub>0</sub> to Prover
This nonce is provided to the Prover for calculation of the Prover's proof of correctness.

##### Prover receives 𝓷<sub>0</sub> and computes the following:
The prover aggregates and prepares public keys for use in validating the signatures. The prover also commits to a chosen value while keeping it temporarily hidden, making the calculation binding.

* Retrieves Issuer’s public key 𝓹𝓴<sub>𝓬</sub>
* Retrieves Issuer’s proof of correctness
* Generates:
    * 𝓶<sub>1</sub> = pedersen commitment of claim link secret
    * Random 𝓿', 𝓿'', 𝓶'<sub>1</sub>
* 𝓷<sub>1</sub> = nonce

##### Prover verifies the Issuer’s proof of correctness:

* 𝓩^ = 𝓩<sup>𝓬</sup>𝓢<sup>𝓧''𝓩</sup> mod 𝓷
* 𝓡^<sub>𝓲</sub> = 𝓡<sub>𝓲</sub><sup>𝓬</sup>𝓢<sup>𝓧''𝓡𝓲</sup> mod 𝓷, 1 ≤ 𝓲  ≤ 𝓵
* Verifies 𝓬 = 𝓗𝓪𝓼𝓱 ( 𝓩 || 𝓡<sub>1</sub> || . . . || 𝓡<sub>𝓵</sub> || 𝓩^ || 𝓡^<sub>1</sub> || . . . || 𝓡^<sub>𝓵</sub> )

##### Prover computes:

* 𝓤 =  𝓢<sup>𝓿’</sup>𝓡<sub>1</sub><sup>𝓶1</sup> mod 𝓷
* 𝓤’ =  𝓢<sup>𝓿’’</sup>𝓡<sub>1</sub><sup>𝓶’1</sup> mod 𝓷
* 𝓬’ = 𝓗𝓪𝓼𝓱 ( 𝓤 || 𝓤’ || 𝓷<sub>0</sub> )
* 𝓿^ = 𝓿’’ + 𝓬’𝓿’
* 𝓶^<sub>1</sub> = 𝓶’<sub>1</sub> + 𝓬’𝓶<sub>1</sub>

##### Prover sends 𝓟 = { 𝓤, 𝓬’, 𝓿^, 𝓶^<sub>1</sub>, 𝓷<sub>1</sub> } to the Issuer

##### Issuer verifies Prover setup
* Computes 𝓤^ = 𝓤<sup>-𝓬</sup>𝓢<sup>𝓿^</sup>𝓡<sub>1</sub><sup>𝓶^<sub>1</sub></sup> mod 𝓷
* Verifies 𝓬’ = 𝓗𝓪𝓼𝓱 ( 𝓤 || 𝓤^ || 𝓷<sub>0</sub> )
##### Issuer signs the credential by computing the following:
* 𝓠 = 𝓩 / (𝓤𝓢<sup>𝓿*</sup>𝓡<sub>2</sub><sup>𝓶2</sup>𝓡<sub>3</sub><sup>𝓶3</sup> ··· 𝓡<sub>𝓵</sub><sup>𝓶𝓵</sup> )  mod 𝓷
* 𝓭 = 𝓮<sup>-1</sup> mod 𝓹’𝓺’
* 𝓐 = 𝓠<sup>𝓭</sup> mod 𝓷
* 𝓐’ = 𝓠<sup>𝓻</sup> mod 𝓷
* 𝓬’’ = 𝓗𝓪𝓼𝓱 (𝓠 || 𝓐 || 𝓐’|| 𝓷<sub>1</sub> )
* 𝓼<sub>𝓮</sub> = (𝓻 - 𝓬’’𝓮<sup>-1</sup>) mod 𝓹’𝓺’
##### Issuer sends 𝓞 = {𝓐, 𝓮, 𝓿*, 𝓼<sub>𝓮</sub>, 𝓬’’, 𝓶<sub>2</sub>, . . . , 𝓶<sub>𝓵</sub> } to the prover
##### Prover receives 𝓞 and does the following:
###### Computes
* 𝓿 = 𝓿’ + 𝓿*
* 𝓠’ = 𝓩 / (𝓢<sup>𝓿</sup>𝓡<sub>2</sub><sup>𝓶2</sup>𝓡<sub>3</sub><sup>𝓶3</sup> ··· 𝓡<sub>𝓵</sub><sup>𝓶𝓵</sup> )  mod 𝓷
* 𝓭’ = 𝓬’’ + 𝓼<sub>𝓮</sub> 𝓮
* 𝓐^ = 𝓐<sup>𝓭’</sup>𝓢<sup>𝓿’𝓼𝓮</sup> mod 𝓷

###### Verifies
* 𝓮 is prime and 2<sup>596</sup> ≤ 𝓮 ≤ 2<sup>596</sup> + 2<sup>119</sup>
* 𝓠’ = 𝓐<sup>𝓮</sup> mod 𝓷
* 𝓬’’ =  𝓗𝓪𝓼𝓱 (𝓠’ || 𝓐 || 𝓐^ || 𝓷<sub>1</sub> )
###### Stores Primary Claim ({𝓶<sub>1</sub>, . . . , 𝓶<sub>𝓵</sub>}, 𝓐, 𝓮, 𝓿)







## Indy SDK
* [Verifiable Credentials Code](https://github.com/hyperledger/indy-sdk/blob/master/libindy/src/api/anoncreds.rs)
* [Verifiable Credentials Example Usage in Python](https://github.com/hyperledger/indy-sdk/blob/master/samples/python/src/anoncreds.py)


# Appendix

Interviews regarding data minimization, selective disclosure and progressive trust.

This section contains definitions we collected that we considered in the formation of our definition above. 

## Data Minimization
Definitions of data minimization that we considered in the formation of our definition above. 

* GDPR Rec.39; Art.5(1)(c) definition: “The personal data should be adequate, relevant and limited to what is necessary for the purposes for which they are processed. This requires, in particular, ensuring that the period for which the personal data are stored is limited to a strict minimum. Personal data should be processed only if the purpose of the processing could not reasonably be fulfilled by other means.”
* Reducing your overall footprint of data outside of your control. Can be accomplished by using selective disclosure. 
* Adequate, relevant and non-excessive.
* Reducing the amount of data you are sending in a payload to only the one is needed. That prevents leakage of confidential information.
* Providing people with the information they need without revealing non necessary info. If I need to prove if I am old enough without revealing an actual birthdate.
* Best practices – your should deeply inspect your use case and come to a conclusion as to what is the minimum data you need to accomplish your goal. Don’t be greedy. Data has proven to be toxic.
* Mathematical – finding a way to express the data that you wish as an equation related to the data you have.
* Minimizing the amount of data to achieve your goal or communicate what you need to.
* Designing systems to operate efficiently in order to maximize privacy.
* Choosing to only share the minimal amount of data about yourself or something during an interaction. 
* Trying to keep the amount of info that is being disclosed as limited as possible to the requirements of the vulnerability. The minimum is what is will lead them to move to action. 
* Always happens in a context: a relationship where the two parties are considering interacting in some way. Sending only the signals that I want to send and that are needed by the other party, hem to interact with me in a particular 
* The least amount of data needed for a system to function
* Collecting the least amount of date for the highest outcome. 
* Also known as minimal disclosure, data minimization is the principle of using the least amount of data to accomplish a transaction. This is incumbent on all three parties in an exchange. The holder should attempt to share the minimum. The issuer needs to create attributes designed for composition and minimal use, as opposed to monolithic credentials with all the data. The verifier needs to ask only for what they need. The motivation to minimize data is that unneeded data is potentially “toxic.” 

## Selective Disclosure

Definitions of selective disclosure that we considered in the formation of our definition above. 

* Ability to decide what info you give and how it can be used.
* Smart disclosure, allows to select what information to give based on logic. 
* Blind search. You can decide who gets to see what. 
* Means by which we achieve data minimization. Form of policies. Ability to mask attributes that you do not have to share.
* Relates to mathematical definition – the computational ability to reveal only parts of your data profile. 
* Act of communicating or revealing only what you intend to, and not any peripheric data
* Having granular control over the ways in which data is shared
* Is a pattern for user interfaces allowing people to choose what to share about them during an interaction
* Method for achieving data minimization where only certain signals are being shared and there is control of who it is being shared with. That control is never perfect. The communication channel matters.
* An entity having granular control on what’s revealed.
* The individual having the freedom to decide what to share, or the acquirer using data minimization approach requesting the minimum amount amount of data for the maximum impact

## Progressive Trust

Definitions of progressive trust that we considered in the formation of our definition above. Note that we included definitions of progressive trust and progressive disclosure as well. 

* Procedure for increasing revelation of relevant data as the communication proceeds. As we continue to communicate we decide to reveal more information. It becomes more generous as trust builds. 
* Being able to reveal more data as you need to given certain conditions
* Information is disclosed as needed when needed.
* You can choose to increase the amount of data you disclose over time as needed. 
* Taking as little vulnerability as possible at the beginning, then gaining information and becoming willing to take on additional vulnerability by revealing more information. 
* Trust is built through step by step interactions where we start making ourselves vulnerable in a very small way and we observe how this works out. Based on results we consider making ourselves further vulnerable or not. It is about increasing levels of familiarity and prediction making (I am better able to predict your behavior). 
* Releasing information as needed
* Escalation of the previous steps (data minimization, selective disclosure) in line with the value increasing. 
* Purpose binding is the auditable use of data, so I can audit the use of my data and determine that it was used for the purposes declared. Progressive trust is the feeling of assurance and safety that develops over time, based on a history of data used only for its bound purposes, and so based on this feeling a data holder will be ready to share more data or other data, if at some point in the relationship this other data is requested. 
* Trust is required when you depend on the actions of someone who you can't control. 

# References:
 * [Data Minimization and Selective Disclosure Repo] (https://github.com/w3c-ccg/data-minimization)
 * Camenisch, Lysyanskaya. [An Efficient System for Non-transferable Anonymous Credentials with Optional Anonymity Revocation] (http://www.cs.ru.nl/~jhh/pub/secsem/camenish2001idemix-clean.pdf)
 * 2010 Pfitzmann, Hansen. [A terminology for talking about privacy by data minimization: Anonymity, Unlinkability, Undetectability, Unobservability, Pseudonymity, and Identity Management] (https://www.researchgate.net/publication/234720523_A_terminology_for_talking_about_privacy_by_data_minimization_Anonymity_Unlinkability_Undetectability_Unobservability_Pseudonymity_and_Identity_Management)
 * 2013 Cooper, Tschofenig, Aboba, Peterson, Morris, Hansen, Smith, Janet. [RFC6973] (https://tools.ietf.org/html/rfc6973). The draft can also be helpful, "This document focuses on introducing terms used to describe privacy properties that support data minimization." 2012 Hansen, Tschofenig, Smith, Cooper. Privacy Terminology and Concepts. Network Working Group Internet-Draft Expires: September 13, 2012. https://tools.ietf.org/html/draft-iab-privacy-terminology-01
 * Redaction Signature Suite 2016, Draft Community Group Report 26 June 2017. Longley, Sporny. Link: https://w3c-dvcg.github.io/lds-redaction2016/ "This specification describes the Redaction Signature Suite created in 2016 for the Linked Data Signatures specification. It enables a sender to redact information in a message without invalidating the digital signature."

